{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb2d624-3572-4827-8bc6-42e0253868a7",
   "metadata": {},
   "source": [
    "# BertForMultipleChoice : Fine-tuning on SWAG with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf72760-ac5b-41c6-9ed7-75b676d5ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b57a692-4f2d-46e3-b5d8-3f884f1fecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Value\n",
    "from DataCollatorForMultipleChoice import DataCollatorForMultipleChoice\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909383a6-cfbf-4d9c-9905-d20659b5f5ef",
   "metadata": {},
   "source": [
    "Hyperparameters from the paper: \"**4.4 SWAG** We fine-tune the model for 3 epochs with a learning rate of 2e-5 and a batch size of 16.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd63c87a-6e69-41a5-a1c1-7dd0bc52a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "weight_decay = 0.01\n",
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce74f62-040c-4574-a71a-3eac5f797c57",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "### Swag: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference\n",
    "**Abstract** : *Given a partial description like “she opened the hood of the car,” humans can reason about the situation and anticipate what might come next (“then, she examined the engine”). In this paper, we introduce the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning. We present Swag, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-theart language models to massively oversample a diverse set of potential counterfactuals. Empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research.*\n",
    "\n",
    "An example of the dataset looks like this:\n",
    "```\n",
    "{\n",
    "    'video-id': 'anetv_jkn6uvmqwh4',\n",
    "    'fold-ind': '3417',\n",
    "    'startphrase': 'A drum line passes by walking down the street playing their instruments. Members of the procession',\n",
    "    'sent1': 'A drum line passes by walking down the street playing their instruments.',\n",
    "    'sent2': 'Members of the procession',\n",
    "    'gold-source': 'gen',\n",
    "    'ending0': 'are playing ping pong and celebrating one left each in quick.',\n",
    "    'ending1': 'wait slowly towards the cadets.',\n",
    "    'ending2': 'makes a square call and ends by jumping down into snowy streets where fans begin to take their positions.',\n",
    "    'ending3': 'play and go back and forth hitting the drums while the audience claps for them.',\n",
    "    'label': 3\n",
    "}\n",
    "```\n",
    "where,\n",
    "- video-id = identification\n",
    "- fold-ind = identification\n",
    "- startphrase = the context to be filled\n",
    "- **sent1** = the first sentence\n",
    "- **sent2** = the start of the second sentence (to be filled)\n",
    "- gold-source = generated or comes from the found completion\n",
    "- **ending0** = first proposition\n",
    "- **ending1** = second proposition\n",
    "- **ending2** = third proposition\n",
    "- **ending3** = fourth proposition\n",
    "- **label** = the correct proposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52476016-fcb0-4ef3-9d28-cbdd48074072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video-id</th>\n",
       "      <th>fold-ind</th>\n",
       "      <th>startphrase</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>gold-source</th>\n",
       "      <th>ending0</th>\n",
       "      <th>ending1</th>\n",
       "      <th>ending2</th>\n",
       "      <th>ending3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3416</td>\n",
       "      <td>Members of the procession walk down the street...</td>\n",
       "      <td>Members of the procession walk down the street...</td>\n",
       "      <td>A drum line</td>\n",
       "      <td>gold</td>\n",
       "      <td>passes by walking down the street playing thei...</td>\n",
       "      <td>has heard approaching them.</td>\n",
       "      <td>arrives and they're outside dancing and asleep.</td>\n",
       "      <td>turns the lead singer watches the performance.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3417</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>Members of the procession</td>\n",
       "      <td>gen</td>\n",
       "      <td>are playing ping pong and celebrating one left...</td>\n",
       "      <td>wait slowly towards the cadets.</td>\n",
       "      <td>continues to play as well along the crowd alon...</td>\n",
       "      <td>continue to play marching, interspersed.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3415</td>\n",
       "      <td>A group of members in green uniforms walks wav...</td>\n",
       "      <td>A group of members in green uniforms walks wav...</td>\n",
       "      <td>Members of the procession</td>\n",
       "      <td>gold</td>\n",
       "      <td>pay the other coaches to cheer as people this ...</td>\n",
       "      <td>walk down the street holding small horn brass ...</td>\n",
       "      <td>is seen in the background.</td>\n",
       "      <td>are talking a couple of people playing a game ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3417</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>Members of the procession</td>\n",
       "      <td>gen</td>\n",
       "      <td>are playing ping pong and celebrating one left...</td>\n",
       "      <td>wait slowly towards the cadets.</td>\n",
       "      <td>makes a square call and ends by jumping down i...</td>\n",
       "      <td>play and go back and forth hitting the drums w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anetv_Bri_myFFu4A</td>\n",
       "      <td>2408</td>\n",
       "      <td>The person plays a song on the violin. The man</td>\n",
       "      <td>The person plays a song on the violin.</td>\n",
       "      <td>The man</td>\n",
       "      <td>gold</td>\n",
       "      <td>finishes the song and lowers the instrument.</td>\n",
       "      <td>hits the saxophone and demonstrates how to pro...</td>\n",
       "      <td>finishes massage the instrument again and cont...</td>\n",
       "      <td>continues dancing while the man gore the music...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            video-id fold-ind  \\\n",
       "0  anetv_jkn6uvmqwh4     3416   \n",
       "1  anetv_jkn6uvmqwh4     3417   \n",
       "2  anetv_jkn6uvmqwh4     3415   \n",
       "3  anetv_jkn6uvmqwh4     3417   \n",
       "4  anetv_Bri_myFFu4A     2408   \n",
       "\n",
       "                                         startphrase  \\\n",
       "0  Members of the procession walk down the street...   \n",
       "1  A drum line passes by walking down the street ...   \n",
       "2  A group of members in green uniforms walks wav...   \n",
       "3  A drum line passes by walking down the street ...   \n",
       "4     The person plays a song on the violin. The man   \n",
       "\n",
       "                                               sent1  \\\n",
       "0  Members of the procession walk down the street...   \n",
       "1  A drum line passes by walking down the street ...   \n",
       "2  A group of members in green uniforms walks wav...   \n",
       "3  A drum line passes by walking down the street ...   \n",
       "4             The person plays a song on the violin.   \n",
       "\n",
       "                       sent2 gold-source  \\\n",
       "0                A drum line        gold   \n",
       "1  Members of the procession         gen   \n",
       "2  Members of the procession        gold   \n",
       "3  Members of the procession         gen   \n",
       "4                    The man        gold   \n",
       "\n",
       "                                             ending0  \\\n",
       "0  passes by walking down the street playing thei...   \n",
       "1  are playing ping pong and celebrating one left...   \n",
       "2  pay the other coaches to cheer as people this ...   \n",
       "3  are playing ping pong and celebrating one left...   \n",
       "4       finishes the song and lowers the instrument.   \n",
       "\n",
       "                                             ending1  \\\n",
       "0                        has heard approaching them.   \n",
       "1                    wait slowly towards the cadets.   \n",
       "2  walk down the street holding small horn brass ...   \n",
       "3                    wait slowly towards the cadets.   \n",
       "4  hits the saxophone and demonstrates how to pro...   \n",
       "\n",
       "                                             ending2  \\\n",
       "0    arrives and they're outside dancing and asleep.   \n",
       "1  continues to play as well along the crowd alon...   \n",
       "2                         is seen in the background.   \n",
       "3  makes a square call and ends by jumping down i...   \n",
       "4  finishes massage the instrument again and cont...   \n",
       "\n",
       "                                             ending3  label  \n",
       "0     turns the lead singer watches the performance.      0  \n",
       "1           continue to play marching, interspersed.      3  \n",
       "2  are talking a couple of people playing a game ...      1  \n",
       "3  play and go back and forth hitting the drums w...      3  \n",
       "4  continues dancing while the man gore the music...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "swag = load_dataset(\"swag\", \"regular\")\n",
    "swag[\"train\"].to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67128231-9783-4a83-b08f-0e7494d4b259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Members of the procession walk down the street holding small horn brass instruments.\n",
      "    A - A drum line passes by walking down the street playing their instruments.\n",
      "    B - A drum line has heard approaching them.\n",
      "    C - A drum line arrives and they're outside dancing and asleep.\n",
      "    D - A drum line turns the lead singer watches the performance.\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "# An example of how a human would view this task\n",
    "example = swag[\"train\"][0]\n",
    "print(f\"{example['sent1']}\\n\\\n",
    "    A - {example['sent2']} {example['ending0']}\\n\\\n",
    "    B - {example['sent2']} {example['ending1']}\\n\\\n",
    "    C - {example['sent2']} {example['ending2']}\\n\\\n",
    "    D - {example['sent2']} {example['ending3']}\\n\\\n",
    "Ground truth: option {['A', 'B', 'C', 'D'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5dd31e-0bca-48e6-b8f4-85d3a8bffe28",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "### Tokenizer\n",
    "\n",
    "\n",
    "We pre-process and tokenize the texts corresponding to the `bert-base-uncased` model architecture. We get three keys: `input_ids`, `token_type_ids` and `attention_mask`.\n",
    "- input_ids = numerical representations of tokens building the sentences\n",
    "- token_type_ids = segment embeddings, indicating which sentence the token belongs to\n",
    "- attention_mask = which tokens should be attended to, and which should not\n",
    "\n",
    "From the paper, \"**4.4 SWAG** *When fine-tuning on the SWAG dataset, we construct four input sequences, each containing the concatenation of the given sentence (sentence `A`) and a possible continuation (sentence `B`). The only task-specific parameters introduced is a vector whose dot product with the `[CLS]` token representation `C` denotes a score for each choice which is normalized with a softmax layer*\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263d3d7e-9ea8-47a6-a2b7-c8d51011708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "endings = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
    "\n",
    "def preprocess_swag(data):\n",
    "    sentA = sum([[A] * 4 for A in data[\"sent1\"]], [])\n",
    "    sentB = sum([[f\"{B} {data[ending][i]}\" for ending in endings] for i, B in enumerate(data[\"sent2\"])], [])\n",
    "    \n",
    "    tokenized_sents = tokenizer(sentA, sentB, truncation=True)\n",
    "    return {k: [v[i:i+4] for i in range(0, len(v), 4)] for k, v in tokenized_sents.items()}\n",
    "\n",
    "encoded_swag = swag.map(preprocess_swag, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b115d507-253b-4bfb-88cd-77e30a1c8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# [tokenizer.decode(encoded_swag[\"train\"][\"input_ids\"][0][i]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac2ba67-6539-4912-b8f8-e07680eb7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "# features = [{k: v for k, v in encoded_swag[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "# batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "# [tokenizer.decode(batch[\"input_ids\"][0][i].tolist()) for i in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055458d-9ef4-46c8-a237-ceeed501f1af",
   "metadata": {},
   "source": [
    "## Model\n",
    "### BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
    "**Abstract**: *We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspecific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).*\n",
    "\n",
    "We evaluate the pre-trained **BERT<sub>BASE</sub>** (L=12, H=768, A=12, Total Parameters=110M), where:\n",
    "- L = number of layers (i.e., Transformer blocks)\n",
    "- H = hidden size\n",
    "- A = number of self-attention heads\n",
    "- Feed-forward/filter size to be 4H, i.e., 3072 for H = 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2c1db79-f7d7-4799-9b7f-361d231775ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611efa6-6f48-44a8-b8ae-018892af3347",
   "metadata": {},
   "source": [
    "The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "717e5ed7-147d-4518-b025-03d99ca1fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include a metric for training\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea2fbd-fd97-4108-bbcd-59b678bbde25",
   "metadata": {},
   "source": [
    "From here, we follow four steps:\n",
    "1. Define training hyperparameters in `TrainingArguments`. At the end of each epoch, the `Trainer` will evaluate the accuracy and save the training checkpoint\n",
    "2. Pass training arguments to `Trainer` along with `model`, `dataset`, `tokenizer`, `data collator`, and `compute_metrics`\n",
    "3. Call `train()` to fine-tune the model\n",
    "4. Evaluate the model on using `evaluate()`/`predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0bb864c-69e4-408c-a84b-7b540d494ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to re-run the fine-tuning process\n",
    "# training_args = TrainingArguments(\n",
    "#     f\"{model_name}-finetuned-swag\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     learning_rate=lr,\n",
    "#     per_device_train_batch_size=batch_size,\n",
    "#     per_device_eval_batch_size=batch_size,\n",
    "#     num_train_epochs=epochs,\n",
    "#     weight_decay=weight_decay,\n",
    "# )\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=encoded_swag[\"train\"],\n",
    "#     eval_dataset=encoded_swag[\"validation\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e33525-c73a-4257-b003-c9f0fc65abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment this if re-running the fine-tuning process\n",
    "model_name = \"chakraborty-de/bert-base-uncased-finetuned-swag\"\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ec8f23-36cf-49be-a5a5-83531c58fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5014' max='2501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2501/2501 04:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchakraborty-de\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/chakraborty.de/CS7150-Final-Project/wandb/run-20231205_000127-jnl11bnt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chakraborty-de/huggingface/runs/jnl11bnt' target=\"_blank\">sage-glade-14</a></strong> to <a href='https://wandb.ai/chakraborty-de/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chakraborty-de/huggingface' target=\"_blank\">https://wandb.ai/chakraborty-de/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chakraborty-de/huggingface/runs/jnl11bnt' target=\"_blank\">https://wandb.ai/chakraborty-de/huggingface/runs/jnl11bnt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.032250165939331,\n",
       " 'eval_accuracy': 0.790962711186644,\n",
       " 'eval_runtime': 76.695,\n",
       " 'eval_samples_per_second': 260.851,\n",
       " 'eval_steps_per_second': 32.61}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment this if re-running the fine-tuning process\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "model.eval()\n",
    "trainer.evaluate(encoded_swag[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d6a5c0-2d8e-4f7c-b5d0-0d9714f9140e",
   "metadata": {},
   "source": [
    "## Problems with the paper and new insights\n",
    "### HellaSwag: Can a Machine Really Finish Your Sentence?\n",
    "**Abstract** : *Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as \"A woman sits at a piano,\" a machine must select the most likely followup: \"She sets her fingers on the keys.\" With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference?\n",
    "In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans (>95% accuracy), state-of-the-art models struggle (<48%). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical 'Goldilocks' zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models.\n",
    "Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.*\n",
    "\n",
    "An example of the dataset looks like this:\n",
    "```\n",
    "{\n",
    "    'ind': 4,\n",
    "    'activity_label': 'Removing ice from car',\n",
    "    'ctx_a': 'Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles.',\n",
    "    'ctx_b': 'then',\n",
    "    'ctx': 'Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. then',\n",
    "    'endings': [\n",
    "        ', the man adds wax to the windshield and cuts it.',\n",
    "        ', a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled.',\n",
    "        ', the man puts on a christmas coat, knitted with netting.',\n",
    "        ', the man continues removing the snow on his car.'\n",
    "    ],\n",
    "    'source_id': 'activitynet~v_-1IBHYS3L-Y',\n",
    "    'split': 'train',\n",
    "    'split_type': 'indomain',\n",
    "    'label': 3\n",
    "}\n",
    "```\n",
    "where,\n",
    "- ind = identification\n",
    "- source_id = identification\n",
    "- activity_label = additional activity context\n",
    "- ctx = the context to be filled\n",
    "- **ctx_a** = the first sentence\n",
    "- **ctx_b** = the start of the second sentence (to be filled)\n",
    "- gold-source = generated or comes from the found completion\n",
    "- **endings** = list of propositions\n",
    "- split = train/validation/test\n",
    "- split_type = indomain/zeroshot\n",
    "- **label** = the correct proposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37b4867e-cdc6-4cac-a3d4-689134494012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>activity_label</th>\n",
       "      <th>ctx_a</th>\n",
       "      <th>ctx_b</th>\n",
       "      <th>ctx</th>\n",
       "      <th>endings</th>\n",
       "      <th>source_id</th>\n",
       "      <th>split</th>\n",
       "      <th>split_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Removing ice from car</td>\n",
       "      <td>Then, the man writes over the snow covering th...</td>\n",
       "      <td>then</td>\n",
       "      <td>Then, the man writes over the snow covering th...</td>\n",
       "      <td>[, the man adds wax to the windshield and cuts...</td>\n",
       "      <td>activitynet~v_-1IBHYS3L-Y</td>\n",
       "      <td>train</td>\n",
       "      <td>indomain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Baking cookies</td>\n",
       "      <td>A female chef in white uniform shows a stack o...</td>\n",
       "      <td>the pans</td>\n",
       "      <td>A female chef in white uniform shows a stack o...</td>\n",
       "      <td>[contain egg yolks and baking soda., are then ...</td>\n",
       "      <td>activitynet~v_-2dxp-mv2zo</td>\n",
       "      <td>train</td>\n",
       "      <td>indomain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Baking cookies</td>\n",
       "      <td>A female chef in white uniform shows a stack o...</td>\n",
       "      <td>a knife</td>\n",
       "      <td>A female chef in white uniform shows a stack o...</td>\n",
       "      <td>[is seen moving on a board and cutting out its...</td>\n",
       "      <td>activitynet~v_-2dxp-mv2zo</td>\n",
       "      <td>train</td>\n",
       "      <td>indomain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>Baking cookies</td>\n",
       "      <td>A tray of potatoes is loaded into the oven and...</td>\n",
       "      <td>a large tray of meat</td>\n",
       "      <td>A tray of potatoes is loaded into the oven and...</td>\n",
       "      <td>[is placed onto a baked potato., , ls, and pic...</td>\n",
       "      <td>activitynet~v_-2dxp-mv2zo</td>\n",
       "      <td>train</td>\n",
       "      <td>indomain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>Getting a haircut</td>\n",
       "      <td>The man in the center is demonstrating a hairs...</td>\n",
       "      <td>the man in the blue shirt</td>\n",
       "      <td>The man in the center is demonstrating a hairs...</td>\n",
       "      <td>[is standing on the sponge cutting the hair of...</td>\n",
       "      <td>activitynet~v_-JqLjPz-07E</td>\n",
       "      <td>train</td>\n",
       "      <td>indomain</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind         activity_label  \\\n",
       "0    4  Removing ice from car   \n",
       "1    8         Baking cookies   \n",
       "2    9         Baking cookies   \n",
       "3   12         Baking cookies   \n",
       "4   27      Getting a haircut   \n",
       "\n",
       "                                               ctx_a  \\\n",
       "0  Then, the man writes over the snow covering th...   \n",
       "1  A female chef in white uniform shows a stack o...   \n",
       "2  A female chef in white uniform shows a stack o...   \n",
       "3  A tray of potatoes is loaded into the oven and...   \n",
       "4  The man in the center is demonstrating a hairs...   \n",
       "\n",
       "                       ctx_b  \\\n",
       "0                       then   \n",
       "1                   the pans   \n",
       "2                    a knife   \n",
       "3       a large tray of meat   \n",
       "4  the man in the blue shirt   \n",
       "\n",
       "                                                 ctx  \\\n",
       "0  Then, the man writes over the snow covering th...   \n",
       "1  A female chef in white uniform shows a stack o...   \n",
       "2  A female chef in white uniform shows a stack o...   \n",
       "3  A tray of potatoes is loaded into the oven and...   \n",
       "4  The man in the center is demonstrating a hairs...   \n",
       "\n",
       "                                             endings  \\\n",
       "0  [, the man adds wax to the windshield and cuts...   \n",
       "1  [contain egg yolks and baking soda., are then ...   \n",
       "2  [is seen moving on a board and cutting out its...   \n",
       "3  [is placed onto a baked potato., , ls, and pic...   \n",
       "4  [is standing on the sponge cutting the hair of...   \n",
       "\n",
       "                   source_id  split split_type  label  \n",
       "0  activitynet~v_-1IBHYS3L-Y  train   indomain      3  \n",
       "1  activitynet~v_-2dxp-mv2zo  train   indomain      3  \n",
       "2  activitynet~v_-2dxp-mv2zo  train   indomain      3  \n",
       "3  activitynet~v_-2dxp-mv2zo  train   indomain      3  \n",
       "4  activitynet~v_-JqLjPz-07E  train   indomain      2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "hella_swag_trn = load_dataset(\"Rowan/hellaswag\", split=\"train\")\n",
    "hella_swag_val = load_dataset(\"Rowan/hellaswag\", split=\"validation\")\n",
    "hella_swag_trn = hella_swag_trn.cast_column(\"label\", Value(dtype='int32', id=None))\n",
    "hella_swag_val = hella_swag_val.cast_column(\"label\", Value(dtype='int32', id=None))\n",
    "hella_swag_trn.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35a138c-b2c7-4cd1-8e04-f53c08c9aa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles.\n",
      "    A - then , the man adds wax to the windshield and cuts it.\n",
      "    B - then , a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled.\n",
      "    C - then , the man puts on a christmas coat, knitted with netting.\n",
      "    D - then , the man continues removing the snow on his car.\n",
      "Ground truth: option D\n"
     ]
    }
   ],
   "source": [
    "# An example of how a human would view this task\n",
    "example = hella_swag_trn[0]\n",
    "print(f\"{example['ctx_a']}\\n\\\n",
    "    A - {example['ctx_b']} {example['endings'][0]}\\n\\\n",
    "    B - {example['ctx_b']} {example['endings'][1]}\\n\\\n",
    "    C - {example['ctx_b']} {example['endings'][2]}\\n\\\n",
    "    D - {example['ctx_b']} {example['endings'][3]}\\n\\\n",
    "Ground truth: option {['A', 'B', 'C', 'D'][example['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a660761-05f8-4fe7-896d-9e17e7bea06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_hella_swag(data):\n",
    "    sentA = sum([[A] * 4 for A in data[\"ctx_a\"]], [])\n",
    "    sentB = sum([[f\"{B}{ending}\" for ending in data[\"endings\"][i]] for i, B in enumerate(data[\"ctx_b\"])], [])\n",
    "    \n",
    "    tokenized_sents = tokenizer(sentA, sentB, truncation=True)\n",
    "    return {k: [v[i:i+4] for i in range(0, len(v), 4)] for k, v in tokenized_sents.items()}\n",
    "\n",
    "encoded_hella_swag_trn = hella_swag_trn.map(preprocess_hella_swag, batched=True)\n",
    "encoded_hella_swag_val = hella_swag_val.map(preprocess_hella_swag, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "266bb614-695d-47b8-845b-392500d73495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# [tokenizer.decode(encoded_hella_swag_trn[\"input_ids\"][0][i]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d9afd7-d4ce-434f-bc6e-35c7d1e590a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "# features = [{k: v for k, v in encoded_hella_swag_trn[i].items() if k in accepted_keys} for i in range(10)]\n",
    "# batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "# [tokenizer.decode(batch[\"input_ids\"][0][i].tolist()) for i in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c3da9-b7e7-48eb-88b1-f8f22527b6c3",
   "metadata": {},
   "source": [
    "### Results on the full validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4aea6af-1a87-4651-890a-755aa53049b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.54646372795105,\n",
       " 'eval_accuracy': 0.32613025293766185,\n",
       " 'eval_runtime': 88.1225,\n",
       " 'eval_samples_per_second': 113.955,\n",
       " 'eval_steps_per_second': 14.253}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(encoded_hella_swag_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9adb9-4ade-4fdd-b81a-b0659a6afc92",
   "metadata": {},
   "source": [
    "### Results on the in-domain (with SWAG) validation (split_type = \"indomain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac29b55c-5c6a-4242-a0fd-7b3152ae8ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.72586727142334,\n",
       " 'eval_accuracy': 0.3311337732453509,\n",
       " 'eval_runtime': 43.0477,\n",
       " 'eval_samples_per_second': 116.174,\n",
       " 'eval_steps_per_second': 14.542}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_hella_swag_val_indomain = encoded_hella_swag_val.filter(lambda x: x[\"split_type\"] == \"indomain\")\n",
    "trainer.evaluate(encoded_hella_swag_val_indomain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be49e99d-d069-411b-92d7-1973b4016c82",
   "metadata": {},
   "source": [
    "### Results on the zero-shot validation (split_type = \"zeroshot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7852d5d-4685-4f80-877e-caa94f57c439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.368483543395996,\n",
       " 'eval_accuracy': 0.32116643523110494,\n",
       " 'eval_runtime': 46.0911,\n",
       " 'eval_samples_per_second': 109.37,\n",
       " 'eval_steps_per_second': 13.69}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_hella_swag_val_zeroshot = encoded_hella_swag_val.filter(lambda x: x[\"split_type\"] == \"zeroshot\")\n",
    "trainer.evaluate(encoded_hella_swag_val_zeroshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849d577-80cf-4639-b57e-5f5b090b640d",
   "metadata": {},
   "source": [
    "A comprehensive comparison of fine-tuning BASE-Base on SWAG dataset, then testing on both SWAG and more difficult HellaSwag:\n",
    "\n",
    "|                         | SWAG   | HellaSwag (Overall) | HellaSwag (In-Domain) | HellaSwag (Zero-Shot) |\n",
    "|-------------------------|--------|---------------------|-----------------------|-----------------------|\n",
    "| **Validation loss**     | 1.032  | 2.546               | 2.725                 | 2.368                 |\n",
    "| **Validation accuracy** | 79.10% | 32.61%              | 33.11%                | 32.11%                |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
